{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erfocentrum Wegwijzer - Complete RAG Chatbot\n",
    "\n",
    "Deze notebook bevat ALLES:\n",
    "1. Website crawlen en scrapen\n",
    "2. Vector store bouwen\n",
    "3. Geoptimaliseerde chatbot met geheugen\n",
    "4. Welkomstflow met privacy-akkoord\n",
    "5. Doorverwijzing naar Erfolijn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 1: Packages installeren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-core langchain-openai langchain-text-splitters langchain-chroma chromadb openai tiktoken beautifulsoup4 requests lxml -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 2: Imports en API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from getpass import getpass\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from collections import deque\n",
    "from typing import List, Dict\n",
    "import re\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# API Key\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 3: Website crawlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_website(start_url, max_pages=200, delay=0.5):\n",
    "    \"\"\"Crawlt de website en verzamelt alle URLs.\"\"\"\n",
    "    parsed_start = urlparse(start_url)\n",
    "    base_domain = parsed_start.netloc\n",
    "    \n",
    "    visited = set()\n",
    "    to_visit = deque([start_url])\n",
    "    found_urls = []\n",
    "    \n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "    \n",
    "    skip_patterns = ['.pdf', '.jpg', '.png', '.gif', '.css', '.js', '/tag/', 'mailto:', 'tel:', \n",
    "                    'facebook.com', 'twitter.com', 'linkedin.com', 'instagram.com', 'youtube.com']\n",
    "    \n",
    "    print(f\"Start crawlen vanaf {start_url}...\")\n",
    "    \n",
    "    while to_visit and len(found_urls) < max_pages:\n",
    "        url = to_visit.popleft()\n",
    "        url = url.split('#')[0].rstrip('/')\n",
    "        \n",
    "        if url in visited or any(p in url.lower() for p in skip_patterns):\n",
    "            continue\n",
    "        \n",
    "        visited.add(url)\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=15)\n",
    "            if 'text/html' not in response.headers.get('Content-Type', ''):\n",
    "                continue\n",
    "            response.raise_for_status()\n",
    "            found_urls.append(url)\n",
    "            \n",
    "            if len(found_urls) % 20 == 0:\n",
    "                print(f\"Gevonden: {len(found_urls)} pagina's\")\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, 'lxml')\n",
    "            for link in soup.find_all('a', href=True):\n",
    "                full_url = urljoin(url, link['href'])\n",
    "                parsed = urlparse(full_url)\n",
    "                if parsed.netloc == base_domain or parsed.netloc == '':\n",
    "                    clean_url = f\"{parsed.scheme}://{parsed.netloc}{parsed.path}\".rstrip('/')\n",
    "                    if clean_url not in visited:\n",
    "                        to_visit.append(clean_url)\n",
    "            \n",
    "            time.sleep(delay)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print(f\"Klaar! {len(found_urls)} pagina's gevonden.\")\n",
    "    return found_urls\n",
    "\n",
    "# Crawl de website\n",
    "all_urls = crawl_website(\"https://erfelijkheid.nl/\", max_pages=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 4: Content scrapen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(url):\n",
    "    \"\"\"Scraped een pagina en extraheert de tekst.\"\"\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n",
    "        'Accept': 'text/html,application/xhtml+xml',\n",
    "        'Accept-Language': 'nl-NL,nl;q=0.9',\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'lxml')\n",
    "        \n",
    "        title_tag = soup.find('title')\n",
    "        title = title_tag.get_text(strip=True) if title_tag else url\n",
    "        \n",
    "        for element in soup(['script', 'style', 'noscript', 'iframe']):\n",
    "            element.decompose()\n",
    "        \n",
    "        body = soup.find('body')\n",
    "        if body:\n",
    "            text = body.get_text(separator=' ', strip=True)\n",
    "        else:\n",
    "            text = soup.get_text(separator=' ', strip=True)\n",
    "        \n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        return {\n",
    "            'url': url,\n",
    "            'title': title,\n",
    "            'content': text,\n",
    "            'success': True\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {'url': url, 'title': '', 'content': '', 'success': False}\n",
    "\n",
    "\n",
    "def scrape_all_pages(urls, delay=0.5):\n",
    "    \"\"\"Scraped alle pagina's.\"\"\"\n",
    "    results = []\n",
    "    total = len(urls)\n",
    "    \n",
    "    print(f\"Scrapen van {total} pagina's...\")\n",
    "    \n",
    "    for i, url in enumerate(urls, 1):\n",
    "        result = scrape_page(url)\n",
    "        if result['success'] and len(result['content']) > 100:\n",
    "            results.append(result)\n",
    "        \n",
    "        if i % 20 == 0:\n",
    "            print(f\"Voortgang: {i}/{total} - Succesvol: {len(results)}\")\n",
    "        \n",
    "        time.sleep(delay)\n",
    "    \n",
    "    print(f\"Klaar! {len(results)} pagina's met content.\")\n",
    "    return results\n",
    "\n",
    "# Scrape alle pagina's\n",
    "scraped_pages = scrape_all_pages(all_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optioneel: Opslaan zodat je niet opnieuw hoeft te scrapen\n",
    "with open('erfocentrum_data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(scraped_pages, f, ensure_ascii=False, indent=2)\n",
    "print(f\"Data opgeslagen: {len(scraped_pages)} pagina's\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 5: Documenten maken en splitten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maak documenten\n",
    "documents = []\n",
    "for page in scraped_pages:\n",
    "    if page.get('content', '').strip():\n",
    "        doc = Document(\n",
    "            page_content=page['content'],\n",
    "            metadata={'source': page['url'], 'title': page['title']}\n",
    "        )\n",
    "        documents.append(doc)\n",
    "\n",
    "# Split in chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Documenten: {len(documents)}, Chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 6: Vector store bouwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vector store bouwen (dit kost een paar cent)...\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "print(\"Vector store klaar!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM instellen\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 7: Chatbot met geheugen en doorverwijzing (GEFIXTE VERSIE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_met_geheugen(vraag: str, geschiedenis: list) -> tuple:\n",
    "    \"\"\"\n",
    "    Beantwoordt een vraag met geheugen van het gesprek.\n",
    "    \n",
    "    BELANGRIJK: De retriever zoekt nu ook op basis van eerdere vragen,\n",
    "    zodat vervolgvragen zoals 'Is het erfelijk?' goed werken.\n",
    "    \"\"\"\n",
    "    \n",
    "    # === FIX: Bouw uitgebreide zoekvraag met context uit gesprek ===\n",
    "    if geschiedenis:\n",
    "        # Neem de laatste vragen mee voor betere zoekresultaten\n",
    "        recente_vragen = [v for v, a in geschiedenis[-3:]]\n",
    "        zoek_query = \" \".join(recente_vragen) + \" \" + vraag\n",
    "        print(f\"   [Debug] Zoekquery: {zoek_query[:80]}...\")  # Debug info\n",
    "    else:\n",
    "        zoek_query = vraag\n",
    "    \n",
    "    # Haal relevante documenten op met de UITGEBREIDE query\n",
    "    docs = retriever.invoke(zoek_query)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    \n",
    "    # Bouw gespreksgeschiedenis voor de prompt\n",
    "    geschiedenis_tekst = \"\"\n",
    "    if geschiedenis:\n",
    "        geschiedenis_tekst = \"\\n\\nEERDERE VRAGEN EN ANTWOORDEN IN DIT GESPREK:\\n\"\n",
    "        for v, a in geschiedenis[-5:]:\n",
    "            # Verwijder bronnen uit geschiedenis voor kortere prompt\n",
    "            a_kort = a.split(\"\\n\\nüìö\")[0].strip()\n",
    "            geschiedenis_tekst += f\"Gebruiker: {v}\\nAssistent: {a_kort}\\n\\n\"\n",
    "    \n",
    "    # Verzamel bronnen\n",
    "    bronnen = set()\n",
    "    for doc in docs:\n",
    "        bronnen.add(doc.metadata.get('source', ''))\n",
    "    \n",
    "    # Prompt met strikte instructies\n",
    "    prompt = f\"\"\"Je bent de Erfocentrum Wegwijzer, een behulpzame assistent die vragen beantwoordt over erfelijkheid en genetica.\n",
    "\n",
    "BELANGRIJKE REGELS:\n",
    "1. Beantwoord ALLEEN vragen op basis van de onderstaande context van erfelijkheid.nl\n",
    "2. Als het antwoord NIET in de context staat, antwoord dan EXACT met alleen: NIET_GEVONDEN\n",
    "3. Als de vraag NIET over erfelijkheid, genetica of erfelijke aandoeningen gaat, antwoord dan EXACT met alleen: NIET_RELEVANT\n",
    "4. Geef nooit persoonlijk medisch advies - verwijs naar een (huis)arts voor persoonlijke situaties\n",
    "5. BELANGRIJK: Kijk naar de gespreksgeschiedenis! Als de gebruiker vraagt \"Is het erfelijk?\" en de vorige vraag ging over dementie, dan gaat de vraag over dementie.\n",
    "6. Antwoord altijd in het Nederlands, bondig en duidelijk\n",
    "{geschiedenis_tekst}\n",
    "CONTEXT UIT ERFELIJKHEID.NL:\n",
    "{context}\n",
    "\n",
    "HUIDIGE VRAAG: {vraag}\n",
    "\n",
    "Antwoord:\"\"\"\n",
    "    \n",
    "    # Genereer antwoord\n",
    "    response = llm.invoke(prompt)\n",
    "    antwoord = response.content\n",
    "    \n",
    "    # Check of doorverwijzing nodig is\n",
    "    if \"NIET_GEVONDEN\" in antwoord or \"NIET_RELEVANT\" in antwoord:\n",
    "        antwoord = \"\"\"Helaas kan ik geen antwoord vinden op je vraag in de informatie van erfelijkheid.nl.\n",
    "\n",
    "Je kunt je vraag stellen aan de deskundigen van het Erfocentrum via de Erfolijn:\n",
    "üëâ https://www.erfelijkheid.nl/contact\n",
    "\n",
    "Zij helpen je graag verder met persoonlijke vragen over erfelijkheid.\"\"\"\n",
    "    else:\n",
    "        # Voeg bronnen toe\n",
    "        if bronnen:\n",
    "            antwoord += \"\\n\\nüìö **Meer informatie:**\\n\"\n",
    "            for bron in list(bronnen)[:2]:\n",
    "                if bron:\n",
    "                    antwoord += f\"- {bron}\\n\"\n",
    "    \n",
    "    # Update geschiedenis\n",
    "    nieuwe_geschiedenis = geschiedenis + [(vraag, antwoord)]\n",
    "    \n",
    "    return antwoord, nieuwe_geschiedenis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 8: Test de chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Gesprek met geheugen - dit zou nu moeten werken!\n",
    "print(\"=\"*60)\n",
    "print(\"TEST 1: Gesprek met geheugen (GEFIXTE VERSIE)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "geschiedenis = []\n",
    "\n",
    "vraag1 = \"Wat is dementie?\"\n",
    "print(f\"\\nüë§ Gebruiker: {vraag1}\")\n",
    "antwoord1, geschiedenis = chat_met_geheugen(vraag1, geschiedenis)\n",
    "print(f\"\\nü§ñ Wegwijzer: {antwoord1}\")\n",
    "\n",
    "# Vervolgvraag - nu zou hij moeten snappen dat het over dementie gaat!\n",
    "vraag2 = \"Is het erfelijk?\"\n",
    "print(f\"\\nüë§ Gebruiker: {vraag2}\")\n",
    "antwoord2, geschiedenis = chat_met_geheugen(vraag2, geschiedenis)\n",
    "print(f\"\\nü§ñ Wegwijzer: {antwoord2}\")\n",
    "\n",
    "# Nog een vervolgvraag\n",
    "vraag3 = \"Hoe groot is de kans dat ik het krijg?\"\n",
    "print(f\"\\nüë§ Gebruiker: {vraag3}\")\n",
    "antwoord3, geschiedenis = chat_met_geheugen(vraag3, geschiedenis)\n",
    "print(f\"\\nü§ñ Wegwijzer: {antwoord3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Niet-relevante vraag\n",
    "print(\"=\"*60)\n",
    "print(\"TEST 2: Niet-relevante vraag\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "vraag_irrelevant = \"Wat is de hoofdstad van Frankrijk?\"\n",
    "print(f\"\\nüë§ Gebruiker: {vraag_irrelevant}\")\n",
    "antwoord, _ = chat_met_geheugen(vraag_irrelevant, [])\n",
    "print(f\"\\nü§ñ Wegwijzer: {antwoord}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 9: Volledige interactieve chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_wegwijzer():\n",
    "    \"\"\"Start de volledige Erfocentrum Wegwijzer met privacy-flow.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üß¨ ERFOCENTRUM WEGWIJZER\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Stap 1: Welkom\n",
    "    print(\"\\nStel je vraag aan de Wegwijzer van het Erfocentrum.\")\n",
    "    print(\"\\n[Start chat]\")\n",
    "    input(\"\\nDruk op Enter om te starten...\")\n",
    "    \n",
    "    # Stap 2: Introductie\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"\"\"Ik help je graag met het zoeken naar algemene informatie \n",
    "over erfelijke ziektes of aandoeningen.\n",
    "\n",
    "‚ö†Ô∏è  Let op: voor een persoonlijk medisch advies kan je het \n",
    "    beste contact opnemen met je (huis)arts.\"\"\")\n",
    "    \n",
    "    # Stap 3: Privacy\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"\"\"Wij vinden jouw privacy heel belangrijk. \n",
    "Bekijk daarom onze privacyverklaring.\n",
    "\n",
    "Ga je hiermee akkoord?\"\"\")\n",
    "    \n",
    "    akkoord = input(\"\\nTyp 'akkoord' of 'niet akkoord': \").lower().strip()\n",
    "    \n",
    "    if 'akkoord' not in akkoord or 'niet' in akkoord:\n",
    "        print(\"\\nJe kunt de chatbot alleen gebruiken als je akkoord gaat.\")\n",
    "        print(\"Bezoek https://www.erfelijkheid.nl voor meer informatie.\")\n",
    "        return\n",
    "    \n",
    "    # Stap 4: Start gesprek\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"Dank voor je akkoord. Waar ben je naar op zoek?\")\n",
    "    print(\"\\n(Typ 'stop' om te stoppen)\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    # Chat loop met geheugen\n",
    "    geschiedenis = []\n",
    "    \n",
    "    while True:\n",
    "        vraag = input(\"\\nüë§ Jij: \").strip()\n",
    "        \n",
    "        if not vraag:\n",
    "            continue\n",
    "        \n",
    "        if vraag.lower() in ['stop', 'quit', 'exit', 'bye']:\n",
    "            print(\"\\nü§ñ Wegwijzer: Bedankt voor je bezoek! Tot ziens.\")\n",
    "            break\n",
    "        \n",
    "        antwoord, geschiedenis = chat_met_geheugen(vraag, geschiedenis)\n",
    "        print(f\"\\nü§ñ Wegwijzer: {antwoord}\")\n",
    "    \n",
    "    # Afsluiting\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚ÑπÔ∏è  De antwoorden zijn gebaseerd op informatie van erfelijkheid.nl,\")\n",
    "    print(\"   zorgvuldig samengesteld en gecontroleerd door medici die\")\n",
    "    print(\"   aangesloten zijn bij het Erfocentrum.\")\n",
    "    print(\"\\nüîí Je gesprek is niet opgeslagen - je privacy is gewaarborgd.\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Start!\n",
    "start_wegwijzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Samenvatting\n",
    "\n",
    "| Functie | Status |\n",
    "|---------|--------|\n",
    "| Titel: Erfocentrum Wegwijzer | ‚úÖ |\n",
    "| Website scrapen | ‚úÖ |\n",
    "| Gesprekgeheugen binnen sessie | ‚úÖ GEFIXED |\n",
    "| Vergeet na sessie (privacy) | ‚úÖ |\n",
    "| Alleen antwoorden uit website-content | ‚úÖ |\n",
    "| Welkomstflow met privacy-akkoord | ‚úÖ |\n",
    "| Doorverwijzing naar Erfolijn | ‚úÖ |\n",
    "| Disclaimer over medici | ‚úÖ |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
